# Multimodal EEG and Speech Biomarker Extraction for MDD Detection

This repository presents an end-to-end multimodal machine learning framework for detecting **Major Depressive Disorder (MDD)** using **electroencephalography (EEG)** and **speech signals**. The project is built on the **MODMA (Multi-Modal Open Dataset for Mental Disorders Analysis)** dataset and integrates neurophysiological and behavioral biomarkers to improve diagnostic robustness and interpretability.

## üîç Key Features
- Audio feature extraction using Librosa and Praat-based voice analysis
- EEG feature extraction from resting-state and ERP signals using MNE-Python
- Subject-level multimodal feature fusion
- Supervised classification using Logistic Regression and Random Forest
- Model serialization using joblib
- Interactive Streamlit dashboard for visualization and prediction

## üß† Motivation
Traditional depression diagnosis relies heavily on subjective assessments. This project aims to provide an **objective, data-driven, and explainable approach** by leveraging multimodal biosignals associated with depressive disorders.

## üìÇ Project Structure
- `notebooks/` ‚Äì Feature extraction and model training notebooks
- `data_processed/` ‚Äì Extracted and integrated feature datasets
- `Model_Output_Joblib/` ‚Äì Trained models and preprocessing pipelines
- `Streamlit/` ‚Äì Deployment dashboard and utilities

## üöÄ Applications
- Mental health research
- Clinical decision support systems
- Multimodal machine learning experimentation

## ‚ö†Ô∏è Disclaimer
This project is intended for research purposes only and is not a substitute for professional medical diagnosis.

-----------------------------------------------------------------------------------------------------------------

## Setup
Link : https://drive.google.com/file/d/1YP4zk7f0UGo6EiwFbtI6qS350J5fXaRT/view?usp=drive_link
